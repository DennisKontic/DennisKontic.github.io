<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>References | AI Security Observer</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .apa-reference {
            padding-left: 36px;
            text-indent: -36px;
            margin-bottom: 1.5rem;
            line-height: 1.8;
        }
    </style>
</head>
<body>
    <header class="site-header">
        <h1>AI Security Observer</h1>
        <p class="subtitle">Tracking the intersection of AI, Cybersecurity, and Red Teaming</p>
        <nav>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="resources.html">Resources</a></li>
                <li><a href="references.html" class="active">References</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section class="featured-post">
            <span class="badge badge-capstone">Project Documentation</span>
            <h2>References</h2>
            <p class="summary" style="margin-bottom: 30px;">
                Formal citations for the AI Security Observer project research, formatted to APA 7th Edition standards.
            </p>

            <div class="reference-list">
                <p class="apa-reference">Kontic, D. (2026). *AI Security Observer*. GitHub Pages. https://denniskontic.github.io</p>
                <p class="apa-reference">Kontic, D. (2026, February 20). *How to red team large language models: A guide to basic testing*. AI Security Observer. https://denniskontic.github.io/posts/red-teaming-llms.html</p>
                <p class="apa-reference">Kontic, D. (2026, February 19). *Essential cybersecurity & AI resources*. AI Security Observer. https://denniskontic.github.io/resources.html</p>
                <p class="apa-reference">Kontic, D. (2026, February 12). *The blue team's guide to LLM attacks: Distinguishing prompt injection from jailbreaking*. AI Security Observer. https://denniskontic.github.io/posts/prompt-injection-guide.html</p>
            </div>
            <a href="index.html" class="read-more">&larr; Back to Home</a>
        </section>
    </main>

    <footer>
        <p>&copy; 2026 Dennis Kontic. Built for Lindenwood University Applied AI.</p>
    </footer>
</body>
</html>
